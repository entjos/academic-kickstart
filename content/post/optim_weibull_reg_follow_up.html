---
title: "Comparing the confidence intervals of a Weibull model estimated with flexsurvreg() and optimx()"
author: "Joshua Philipp Entrop"
date: '2020-10-25'
output: html_document
categories: [Optimisation, R]
tags: [R, survival analysis, manual optimisation]
draft: FALSE
---



<p>This blog post is a follow up on my <a href="https://www.joshua-entrop.com/post/optim_weibull_reg/">previous post</a> on optimising a Weibull regression model using <TT>optimx()</TT>. This time I’ll try to find a solution for the discrepancy between the confidence interval estimates of the Weibull hazard function estimated with <TT>optimx()</TT> and <TT>flexsurvreg()</TT>.</p>
<p>This post begins where my previous one ended. Hence, I suggest you to read my <a href="https://www.joshua-entrop.com/post/optim_weibull_reg/">previous post</a> before reading this one. Also, I will use the <TT>R</TT> script of my previous post as starting point for this post. You can find the whole plain <TT>R</TT> script used in this post in <TT>.txt</TT> format <a href="https://www.joshua-entrop.com/rcode/optim_weibull_reg_follow_up.txt">here</a>.</p>
<p><img src="/post/optim_weibull_reg_follow_up_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>This is the figure where my last post ended. I compared the hazard function <span class="math inline">\(h(t)\)</span> of the Weibull model estimated manually using <TT>optimx()</TT> with the hazard function of an identical model estimated with <TT>flexsurvreg()</TT>. Interestingly, the hazard functions were identical, but there were considerable differences in the estimates of the confidence intervals across follow-up time, as you can see in the figure above. Unfortunately, I couldn’t come up with an explanation for this discrepancy. However, I was lucky and got help from <a href="https://staff.ki.se/people/anddis">Andrea Discacciati</a>, a colleague at Karolinska Institutet. He pointed out that the <TT>flexsurvreg()</TT> function from the <TT>{flexsurvreg}</TT> package uses the log-hazard function (<span class="math inline">\(\ln h(t)\)</span>) for estimating confidence intervals whereas I used the hazard function (<span class="math inline">\(h(t)\)</span>) in my post instead. Working on the log-scale allows to transform the multiplicative components of the hazard function into additive components, since <span class="math inline">\(\ln xy = \ln x + \ln y\)</span>. This is usually done to increase the precision of the computation process, since multiplication usually comes with a higher loss in precision compared to summation. Hence, using the hazard function instead of the log-hazard function might lead to the difference in the estimates for the confidence intervals of the hazard functions, that we can see in the figure above.</p>
<p>So let’s try to use the log-hazard instead of the hazard for the computation of our survival function together with its confidence intervals. First the hazard function is, as explained in my previous post, defined by</p>
<p><span class="math display">\[
h(t) = \gamma \lambda t ^{\gamma - 1}.
\]</span></p>
<p>Let’s then compute the hazard function and the confidence intervals using the hazard function on the identity scale.</p>
<pre class="r"><code># 12. Compare h(t) with CIs using identity and log-scale ----------------------

# Get coefficents for Newuoa optimisation
newuoa_coef &lt;- coef(opt)[&quot;newuoa&quot;, ]

# 12.1 Estimate h(t) with CIs using hazard function on identity scale =========

# Compute CIs for a 60 year old female across time
haz_optim_female &lt;- lapply(as.list(seq(0.01, 1000.01, 10)), function(t){
  
  g &lt;- paste(&quot;exp(gamma) * exp(alpha + beta_female + 60 * beta_age) *&quot;, t,
             &quot;^ (exp(gamma) - 1)&quot;)
  
  fit &lt;- deltaMethod(newuoa_coef, g, solve(hessian_m))
  
  data.frame(time     = t,
             estimate = fit[, &quot;Estimate&quot;],
             ci_low   = fit[, &quot;2.5 %&quot;],
             ci_up    = fit[, &quot;97.5 %&quot;])
  
}) %&gt;%
  bind_rows()</code></pre>
<p>In the next step we need to compute the hazard function and its confidence interval on the log-scale <span class="math inline">\(\ln h(t)\)</span>. The log-hazard function can be written as</p>
<p><span class="math display">\[
\ln h(t) = \ln \gamma + \ln \lambda + \ln t  (\exp(\gamma) - 1).
\]</span></p>
<p>Let’s use this formula to calculate the confidence interval of the hazard function using the same function as above.</p>
<pre class="r"><code># 12.2 Estimate h(t) with CIs using hazard function on log scale ==============

# Compute CIs for a 60 year old female across time
haz_optim_female_log &lt;- lapply(as.list(seq(0.01, 1000.01, 10)), function(t){
  
  g &lt;- paste(&quot;(gamma) + (alpha + beta_female + 60 * beta_age) +&quot;, log(t),
             &quot;* (exp(gamma) - 1)&quot;)
  
  fit &lt;- deltaMethod(newuoa_coef, g, solve(hessian_m))
  
  data.frame(time     = t,
             estimate = exp(fit[, &quot;Estimate&quot;]),
             ci_low   = exp(fit[, &quot;2.5 %&quot;]),
             ci_up    = exp(fit[, &quot;97.5 %&quot;]))
  
}) %&gt;%
  bind_rows()</code></pre>
<p>We can now compare the confidence intervals obtained by these two different computations by plotting their hazard functions and confidence intervals.</p>
<pre class="r"><code># 12.3 Create plot comparing both estimations =================================

par(mfcol = c(1, 2))

# 10.2 Plot hazard curve with CIs =============================================

# create list of both data frames

list_haz_optim_female &lt;- list(haz_optim_female,
                              haz_optim_female_log)

invisible(
mapply(df = list(haz_optim_female, haz_optim_female_log),
       titles = c(&quot;Based on hazard function&quot;,
                  &quot;Based on log-hazard function&quot;),
       FUN = function(df, titles){
         
         plot(df$time,
              df$estimate,
              ylim = c(0, 0.005),
              type = &quot;n&quot;,
              xlab = &quot;Time in Days&quot;,
              ylab = &quot;h(t)&quot;,
              main = titles)
         polygon(c(df$time, rev(df$time)),
                 c(df$ci_low, rev(df$ci_up)),
                 border = NA,
                 col = &quot;grey&quot;)
         plot(weibull_model, type = &quot;hazard&quot;,
              newdata = data.frame(age = 60,
                                   female = 1),
              add = TRUE)
         lines(df$time,
               df$estimate)
         legend(&quot;topleft&quot;,
                inset = 0.01,
                cex = 0.8,
                fill = c(&quot;black&quot;, &quot;red&quot;),
                legend = c(&quot;Optimix()&quot;, &quot;flexsurvreg()&quot;),
                box.lty = 0)
       })
)</code></pre>
<p><img src="/post/optim_weibull_reg_follow_up_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>In this figure we can see the hazard function and its confidence interval (gray area) for both computation approaches. The estimates yielded by working on the identity scale are shwon on the left and the estimates yieled by working on the log-scale are shown on the right. At the same time we see the estimates yielded by estimating the same model with <TT>flexsurvreg()</TT> (red lines). As we can see, working on the log-scale yielded estimates very much closer to the estimates obtained with <TT>flexsurvreg()</TT> compared to the model using the identity scale.</p>
<p>Hence, it seems as this difference between working on the identity and log-scale for computing the confidence intervals may explain a big part of the discrepancy between the confidence intervals obtained with <TT>flexsurvreg()</TT> and <TT>optimx()</TT>, which we can see in the first figure above. The remaining differences are likely due to the fact, that the <TT>flexsurvreg()</TT> function uses the bootstrap method instead of the delta method to estimate confidence intervals for the hazard function.</p>
<p>In this post we compared the confidence intervals of a hazard function obtained by applying the delta method to the hazard function on the identity scale (<span class="math inline">\(h(t)\)</span>) and on the log-scale (<span class="math inline">\(\ln h(t)\)</span>). As <a href="https://staff.ki.se/people/anddis">Andrea Discacciati</a> pointed out both approaches assymptotically yield the same results. However, working on the log-hazard scale is favorable for finite samples.</p>
